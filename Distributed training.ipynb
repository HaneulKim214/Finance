{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13029221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7957dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.11 (default, Jul 27 2021, 09:42:29) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "866c3d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randint(10, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c7a1380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "078621cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for e in ds:\n",
    "    n += e.numpy()\n",
    "    print(e)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a73e60b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a015b949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.iterator_ops.OwnedIterator"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45533a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a354365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - ds2 - - - - - - - -\n",
      "tf.Tensor(\n",
      "[[0.47324824 0.5358292  0.68424356 0.6670543  0.39903927 0.74895215\n",
      "  0.02241492 0.7940999  0.96831155 0.3296466 ]\n",
      " [0.90393615 0.21639478 0.00346696 0.00973201 0.59110105 0.6534457\n",
      "  0.34532034 0.44684315 0.7754146  0.75971067]\n",
      " [0.05918646 0.92768335 0.08951044 0.5959326  0.1223489  0.64387894\n",
      "  0.623575   0.88988674 0.25609267 0.93290424]\n",
      " [0.13810718 0.28943217 0.4182005  0.46913886 0.93926716 0.7865521\n",
      "  0.10096097 0.37386072 0.5458963  0.89973044]], shape=(4, 10), dtype=float32)\n",
      "- - - - - - - - ds3 - - - - - - - -\n",
      "(<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.19898903, 0.833717  , 0.17857337, 0.19229329], dtype=float32)>, <tf.Tensor: shape=(4, 4), dtype=int32, numpy=\n",
      "array([[72, 98, 32, 86],\n",
      "       [80,  9, 44,  6],\n",
      "       [70, 44, 42, 35],\n",
      "       [21, 42, 71, 76]])>)\n"
     ]
    }
   ],
   "source": [
    "ds2 = tf.data.Dataset.from_tensor_slices(tf.random.uniform([4,10]))\n",
    "\n",
    "print(\"- - - - - - - - ds2 - - - - - - - -\")\n",
    "print(tf.random.uniform([4,10]))\n",
    "ds3 =(tf.random.uniform([4]),\n",
    "      tf.random.uniform([4, 4], maxval=100, dtype=tf.int32))\n",
    "\n",
    "print(\"- - - - - - - - ds3 - - - - - - - -\")\n",
    "print(ds3)\n",
    "ds3 = tf.data.Dataset.from_tensor_slices(ds3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f21a777e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorSpec(shape=(), dtype=tf.int32, name=None)\n",
      "TensorSpec(shape=(10,), dtype=tf.float32, name=None)\n",
      "(TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "print(ds.element_spec)\n",
    "print(ds2.element_spec)\n",
    "print(ds3.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4e965e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for e in tf.data.Dataset.range(3):\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "017f6481",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_ds = tf.data.Dataset.range(100)\n",
    "inc_ds2 = tf.data.Dataset.range(100, 200)\n",
    "comb_ds = tf.data.Dataset.zip((inc_ds, inc_ds2))\n",
    "batch_ds = comb_ds.batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f472395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor: shape=(), dtype=int64, numpy=0>,\n",
       "  <tf.Tensor: shape=(), dtype=int64, numpy=100>),\n",
       " (<tf.Tensor: shape=(), dtype=int64, numpy=1>,\n",
       "  <tf.Tensor: shape=(), dtype=int64, numpy=101>),\n",
       " (<tf.Tensor: shape=(), dtype=int64, numpy=2>,\n",
       "  <tf.Tensor: shape=(), dtype=int64, numpy=102>)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(iter(comb_ds))[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bf92c2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)>, <tf.Tensor: shape=(10,), dtype=int64, numpy=array([100, 101, 102, 103, 104, 105, 106, 107, 108, 109], dtype=int64)>)\n"
     ]
    }
   ],
   "source": [
    "for e in batch_ds: # this continues until all elements \n",
    "    print(e) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1fd81189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)>, <tf.Tensor: shape=(10,), dtype=int64, numpy=array([100, 101, 102, 103, 104, 105, 106, 107, 108, 109], dtype=int64)>)\n",
      "(<tf.Tensor: shape=(10,), dtype=int64, numpy=array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19], dtype=int64)>, <tf.Tensor: shape=(10,), dtype=int64, numpy=array([110, 111, 112, 113, 114, 115, 116, 117, 118, 119], dtype=int64)>)\n"
     ]
    }
   ],
   "source": [
    "for e in batch_ds.take(2): # only take(n), n element within ds.\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "405b523c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSince each element may be different length, especially in sequential models. tf provide Dataset.padded_batch\\nfunction\\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Since each element may be different length, especially in sequential models. tf provide Dataset.padded_batch\n",
    "function\n",
    "\"\"\"\n",
    "# dataset = tf.data.Dataset.range(100)\n",
    "# dataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))\n",
    "# dataset = dataset.padded_batch(4, padded_shapes=(None,))\n",
    "\n",
    "# for batch in dataset.take(2):\n",
    "#     print(batch.numpy())\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8795282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccb98aab",
   "metadata": {},
   "source": [
    "Petastorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17ebeedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_path = '../datasets/h&m/transaction_train_sample.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "153584ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\haneu\\\\Desktop\\\\PROJECTS\\\\Finance'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join('file://', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6dd5b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file://C:\\\\Users\\\\haneu\\\\Desktop\\\\PROJECTS\\\\Finance'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'file://' + os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fda8e1b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\haneu\\\\Desktop\\\\PROJECTS\\\\Finance\\\\parquet_files'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(os.getcwd(), 'parquet_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a952bd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\haneu\\\\Desktop\\\\PROJECTS\\\\Finance\\\\parquet_files'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(\"file://\", os.path.join(os.getcwd(), 'parquet_files'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6e500782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from petastorm import make_reader, make_batch_reader\n",
    "from petastorm.tf_utils import make_petastorm_dataset\n",
    "\n",
    "# filepath = 'file://parquet_files'\n",
    "filepath = os.path.join(\"file://\", os.path.join(os.getcwd(), 'parquet_files'))\n",
    "filepath = \"file:///Users/haneu/Desktop/PROJECTS/Finance/parquet_files\"\n",
    "print(filepath)\n",
    "with make_reader(dataset_url=filepath) as reader:\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "febe46bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function make_petastorm_dataset.<locals>.set_shape at 0x0000025775DA98B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function make_petastorm_dataset.<locals>.set_shape at 0x0000025775DA98B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "with make_batch_reader(dataset_url_or_urls=filepath) as reader:\n",
    "    dataset = make_petastorm_dataset(reader)\n",
    "#     for row in reader:\n",
    "#         print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a85e0fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inferred_schema_view(t_dat=TensorSpec(shape=(None,), dtype=tf.string, name=None), customer_id=TensorSpec(shape=(None,), dtype=tf.string, name=None), article_id=TensorSpec(shape=(None,), dtype=tf.int64, name=None), price=TensorSpec(shape=(None,), dtype=tf.float64, name=None), sales_channel_id=TensorSpec(shape=(None,), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a7ff9900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.DatasetV1Adapter"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8e5d1b82",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "RuntimeError: Trying to read a sample after a reader created by make_reader/make_batch_reader has stopped. This may happen if the make_reader/make_batch_reader context manager has exited but you try to fetch a sample from it anyway\nTraceback (most recent call last):\n\n  File \"C:\\Users\\haneu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 275, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\haneu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 649, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\haneu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 992, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\haneu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\petastorm\\tf_utils.py\", line 380, in dequeue_sample_impl\n    for row in reader:\n\n  File \"C:\\Users\\haneu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\petastorm\\reader.py\", line 690, in __next__\n    raise RuntimeError('Trying to read a sample after a reader created by '\n\nRuntimeError: Trying to read a sample after a reader created by make_reader/make_batch_reader has stopped. This may happen if the make_reader/make_batch_reader context manager has exited but you try to fetch a sample from it anyway\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18404\\1085007631.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    798\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    784\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   2842\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2843\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2844\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2845\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2846\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7105\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7106\u001b[0m   \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7107\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: RuntimeError: Trying to read a sample after a reader created by make_reader/make_batch_reader has stopped. This may happen if the make_reader/make_batch_reader context manager has exited but you try to fetch a sample from it anyway\nTraceback (most recent call last):\n\n  File \"C:\\Users\\haneu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 275, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\haneu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 649, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\haneu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 992, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\haneu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\petastorm\\tf_utils.py\", line 380, in dequeue_sample_impl\n    for row in reader:\n\n  File \"C:\\Users\\haneu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\petastorm\\reader.py\", line 690, in __next__\n    raise RuntimeError('Trying to read a sample after a reader created by '\n\nRuntimeError: Trying to read a sample after a reader created by make_reader/make_batch_reader has stopped. This may happen if the make_reader/make_batch_reader context manager has exited but you try to fetch a sample from it anyway\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "for e in dataset:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a57449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
